---
title: "Final Project"
author: "Bernardo Magalhaes, Adhish Luitel, Ji Heon Shim"
date: "`r format(Sys.Date())`" 
always_allow_html: true
output:
    md_document:
    variant: markdown_github
---
#ECO 395M: Final Project
## Using Machine Learning literature to predict counterfactuals: an alternative method to Differences-in-Differences estimation

Bernardo Arreal Magalhaes - UTEID ba25727

Adhish Luitel - UTEID al49674

Ji Heon Shim - UTEID js93996

## Abstract

In this project, we looked into the effect of prison expansion across various prisons in the state of Texas. To assess the causal effect of increased prison capacity on black male population incarceration, we first used the difference-in-difference estimator to see the validity of the parallel trends assumption. Then, in order to overcome the limitations of difference in difference, we explored three alternative predictive analysis models, i.e. Lasso regression, Random Forests, and Boosting model respectively to test their performances via K-fold validation to determine the most accurate model. As a result, our model fits very well on real data suggesting the high possibility of predicting counterfactuals.

## Introduction

```{r setup1, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(knitr)
library(tidyverse)
library(haven)
library(stargazer)
library(lmtest)
library(lfe)
library(xtable)
library(tidytable)
library(grid)
library(car)
library(dummies)
library(gbm)
library(gamlr)
library(randomForest)
library(kableExtra)
library(mosaic)
library(pander)

texas = read.csv("https://raw.githubusercontent.com/bmagalhaes/ECO395M-Final-Project/master/texas.csv")

table1_url = 'https://raw.githubusercontent.com/bmagalhaes/ECO395M-Final-Project/master/4.0-table1.png'

graph1_url = 'https://raw.githubusercontent.com/bmagalhaes/ECO395M-Final-Project/master/4.0-graph1.png'
```

Assessing policy effects and making predictions based on it has always been a key part of quantitative economics. Empirical economists are very often interested in estimating the impact of certain events or policies on a particular outcome. Wooldridge (2013) describes the effectiveness applications of Differences-in-Differences methodology when the data arise from a natural experiment. This kind of experiment occurs when an exogenous event changes the environment in which individuals operate, and require observations of both treatment and control group before and after the change.

This methodology is particularly powerful for inferring causality since it neutralizes unobserved, but fixed, omitted variables (Angrist and Pischke, 2018). Nonetheless, it relies on a quite strong – and unfortunately not testable – assumption that the outcome in the multiple individuals/firms/states included in the analysis share the same trend over time, which is called parallel trends assumption.

The table below illustrates a simple version of the Diff-in-Diff method and why this assumption is required. By decreasing the outcome after treatment from the outcome before treatment for a treated state, the difference (D1) is going to be the effect caused by the treatment (E) plus a trend (T). This step neutralizes unobserved factors of a particular state. For a state that wasn't treated, the difference (D1) before and after treatment is the trend (T) only. So, if we assume that T is the same for both states, we can decrease T, that was measured from the control state, from T + E in order to isolate the causal effect E.

```{r 4.1.1, echo= FALSE, warning = FALSE}
include_graphics(table1_url)
```

This assumption is not testable because we don’t know what would’ve happened to the treatment state had it never been treated.

But what if we could predict what would have happened to the treated state in this alternative world where it wasn’t treated without having to rely on the parallel trends assumption? 

In order to do that, we analyzed the application of a set of predictive models such as Lasso Regression, RandomForest and Boosting in a particular research topic, and adopted the best predictive model to predict counterfactuals without having to rely on the parallel trends assumption.

### Research topic brief summary

During the 1980s, the state of Texas lost a civil action lawsuit where a prisoner argued that the state Department of Corrections was engaging in unconstitutional practices regarding prisoners conditions. The court ruled in favor of the prisoner, and forced the state to  pursue a series of settlements. Among other orders, the court placed constraints on the number of inmates allowed per cells. Given this constraint, state legislators approved a billion dollar prison construction project that ended up doubling the state’s capacity within 3 years.

```{r 4.1.2, echo= FALSE, warning = FALSE}
include_graphics(graph1_url)
```

Cunningham (2020) argues that the nature of this expansion allows us to use it as a natural experiment to estimate the effect of prison expansion on incarceration. He uses the synthetic control method to predict counterfactuals as in Abadie et al. (2010) by searching for the set of weights that generate the best fitting convex combination of the control units, being the best the one that minimizes root mean square error in the pre-treatment period.

His preliminary results indicate that an increase in state prison capacity caused an increase in black male incarceration. Bearing this in mind, we used a set of alternative methods learned in class to estimate counterfactuals and, therefore, measure the causal effect.

## Method

In this project, we used a standard Diff-in-Diff model, and compared its results with the simple difference in outcomes predicted by the alternative method that yields the best out of sample predictive power among multiple train-test splits.

With some evidence that the Diff-in-Diff assumptions might not hold, a prominent supervised learning modelling method hopefully might predict counterfactuals with more precision and produce more robust and accurate results. Bearing the characteristics of our dataset in mind, we decided to conduct iterative model selection and utilize regularization based methods to identify the best working model.

This dataset contains observations of various prisons across all the states in the country from 1985 to 2000. So the variable year is continuous over the 15 year period. With the races primarily divided into black and white, this dataset deals with various factors that could possibly contribute to crime and the share of African American population in the state of Texas. In light of this, variables like alcohol consumption per capita (alcohol), aids mortality (aidscapita), average household income (income), unemployment rate (ur), share of the population in poverty (poverty), share of the population which is African American (black) and the share of the population which is 15 to 19 years old (perc1519) were considered. Since we were looking at increased incarceration among the black male population with prison capacity increase,  number of black male prisoners (bmprison) was our dependent variable. 

## RESULTS

### Differences-in-Differences

In order to have a baseline model which preserve the same parameters that were included in Cunningham's analysis, the Diff-in-Diff model is:

```{r 4.2.1, echo= TRUE, warning = FALSE}
# bmprison ~ alcohol + aidscapita + income + ur + poverty + black + perc1519 + year + state + year_after1993*state_texas
```

The model indicates that the expansion of the state prison capacity is associated with an increase of 28,454.82 black male prisoners, holding all else fixed.

```{r 4.2.2, echo=FALSE, warning=FALSE}
texas$post = ifelse(texas$statefip == 48 & texas$year >= 1993, 1, 0)

texas = texas %>%
  mutate(year_fixed = as_factor(year)) %>%
  mutate(statefip = as_factor(statefip))

fe_lm = felm(bmprison ~ post + alcohol + aidscapita + income + ur + poverty + 
               black + perc1519 | year_fixed + statefip | 0 | 0, data=texas)

stargazer(fe_lm, type = 'text',
          covariate.labels = "Prison capacity expansion",
          omit = c("alcohol", "aidscapita", "income", "ur", "poverty",
                   "black", "perc1519"),
          dep.var.labels = "Black Male Prisoners",
            add.lines = list(c("State Fixed effects", "Yes"),
                           c("Year Fixed effects", "Yes")),
          omit.stat = "ser")
```

When decomposing the effect in each year, we get the point estimates shown in the figure below. The coefficients capture how the treatment group differs from the control group when controlling for multiple factors and when considering state and year fixed effects. It also allows us the test the plausibility of parallel trends in the pre-treatment period. As we are including controls and fixed effects, there should be less to be explained by the coefficients to the left of the grey vertical line since the only difference should be the treatment itself, and it didn't occur in years prior to the intervention.

```{r 4.2.3, echo=FALSE, warning=FALSE}
texas = texas %>%
  mutate(time_til = ifelse(statefip == 48, year - 1993, 0),
    lead1 = case_when(time_til == -1 ~ 1, TRUE ~ 0),
    lead2 = case_when(time_til == -2 ~ 1, TRUE ~ 0),
    lead3 = case_when(time_til == -3 ~ 1, TRUE ~ 0),
    lead4 = case_when(time_til == -4 ~ 1, TRUE ~ 0),
    lead5 = case_when(time_til == -5 ~ 1, TRUE ~ 0),
    lead6 = case_when(time_til == -6 ~ 1, TRUE ~ 0),
    lead7 = case_when(time_til == -7 ~ 1, TRUE ~ 0),
    lead8 = case_when(time_til == -8 ~ 1, TRUE ~ 0),
    lag0 = case_when(time_til == 0 ~ 1, TRUE ~ 0),
    lag1 = case_when(time_til == 1 ~ 1, TRUE ~ 0),
    lag2 = case_when(time_til == 2 ~ 1, TRUE ~ 0),
    lag3 = case_when(time_til == 3 ~ 1, TRUE ~ 0),
    lag4 = case_when(time_til == 4 ~ 1, TRUE ~ 0),
    lag5 = case_when(time_til == 5 ~ 1, TRUE ~ 0),
    lag6 = case_when(time_til == 6 ~ 1, TRUE ~ 0),
    lag7 = case_when(time_til == 7 ~ 1, TRUE ~ 0)
  )

fe_leads = felm(bmprison ~ lead1 + lead2 + lead3 + lead4 + lead5 + lead6 + lead7
                + lead8 + lag1 + lag2 + lag3 + lag4 + lag5 + lag6 + lag7
                + alcohol + aidscapita + income + ur + poverty + black + perc1519
                | year_fixed + statefip | 0 | 0, data=texas)

plot_order <- c("lead8", "lead7", "lead6", "lead5", "lead4", "lead3", "lead2",
                "lead1", "lag1", "lag2", "lag3", "lag4", "lag5", 
                "lag6", "lag7")

leadslags_bmprison <- tibble(
  sd = c(fe_leads$se[plot_order], 0),
  mean = c(coef(fe_leads)[plot_order], 0),
  label = c(-8, -7, -6, -5, -4, -3, -2, -1, 1, 2, 3, 4, 5, 6, 7, 0)
)

leadslags_bmprison %>%
  ggplot(aes(x = label, y = mean, ymin = mean-1.96*sd, ymax = mean+1.96*sd)) +
  geom_point(color = "dark blue") +
  geom_line(aes(y = mean+1.96*sd, x=label), colour = 'dark blue', linetype = "dashed") +
  geom_line(aes(y = mean-1.96*sd, x=label), colour = 'dark blue', linetype = "dashed")+
  geom_line(color = "dark blue") +
  geom_ribbon(alpha = 0.4, fill = "light blue") +
  theme_bw() +
  xlab("Years Relative to Prison Expansion") +
  ylab("Black Male Prison") +
  geom_hline(yintercept = 0, color = "dark grey", size = 0.8) +
  geom_vline(xintercept = 0, color = "dark grey", size = 0.8) +
  geom_hline(yintercept = 28454.8160032, color = "red", size = 1.2) +
  scale_x_continuous(breaks= c(-8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7)) +
  theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank())
```

A test of joint significance of the leads coefficients, as in Kearney and Levine (2015), reject the null hypothesis that they are jointly equal to zero (p-value = 0.006). Therefore, it provides evidence that the parallel trends assumption doesn't hold even in the pre-treatment period, indicating the necessity of exploring different methods.

```{r 4.2.4, echo=FALSE, warning=FALSE}
f_test = linearHypothesis(fe_leads, c("lead1 = lead2",
                                                "lead2 = lead3",
                                                "lead3 = lead4",
                                                "lead4 = lead5",
                                                "lead5 = lead6",
                                                "lead6 = lead7",
                                                "lead7 = 0"))

stargazer(f_test, flip = TRUE, type = 'text', summary.stat = c("mean"))
```

Therefore, we tested 3 alternative models to find out the best predictive one other than assuming the parallel trends. As mentioned before, we used Lasso regression, RandomForest, and Boosting model respectively and tested their performances by K-fold validation.

### Lasso Regression

First, we fit a lasso regression. From the baseline model we used in diff-in-diff analysis, we added one more variable - 'crack', hoping it can enhance our model's predictive power, and considered all possible interactions. Running the lasso regression model, the path plot is shown on [Graph 2].

```{r 4.3.2, echo=FALSE, warning=FALSE}
texas_train = subset(texas, post == 0)
texas_lasso <- dummy.data.frame(texas_train, names = c("statefip", "year_fixed"))
texas_lasso$statefip = texas_train$statefip
texas_lasso$year_fixed = texas_train$year_fixed
texas_x = sparse.model.matrix(bmprison ~ (crack + alcohol + income + ur + poverty + black  + perc1519 + aidscapita + year_fixed + statefip)^2, data=texas_lasso)[, -1]
texas_y = texas_lasso$bmprison
reg_lasso = gamlr(texas_x, texas_y)
plot(reg_lasso, main = "[Graph 2] Lasso Model")
```

As a result, we obtained a model with 181 variables with an intercept. Then we did K-fold cross validation to check RMSE when K is 10. We used a train-test split and repeated the step from 1 to K repetitions by running a loop. Our train set and test set were both subsets of our whole dataset except the observations from the state of Texas after 1993, which is what we want to predict. By doing it, we can measure how the model estimate the change of black male prisoners which is not affected by the policy implementation.`

```{r 4.3.3, echo=FALSE, include=FALSE}
texas_lasso_beta = coef(reg_lasso)
sum(texas_lasso_beta!=0)
p1 <- dimnames(texas_lasso_beta)[[1]]
p1
p2 <- c()
p2
for (i in c(1:length(texas_lasso_beta))){
  p2 <- c(p2, as.list(texas_lasso_beta)[[i]])
}
model_lasso = c("bmprison ~ ")
for (i in c(2:length(texas_lasso_beta))){
  if (p2[i] != 0){
    if (model_lasso == "bmprison ~ "){
      model_lasso = paste(model_lasso, p1[i])
    }
    else{
      model_lasso = paste(model_lasso,"+", p1[i])
    }
  }
}
model_lasso <- as.formula(model_lasso)
model_lasso = lm(model_lasso, data=texas_lasso)

N=nrow(texas_train)
K=10
fold_id = rep_len(1:K, N)
fold_id = sample(fold_id, replace = FALSE)
err_save_lasso = rep(0, K)
for(i in 1:K){
  train_set = which(fold_id != i)
  y_test = texas_lasso$bmprison[-train_set]
  yhat_test = predict(model_lasso, newdata = texas_lasso[-train_set,])
  err_save_lasso[i] = mean((y_test-yhat_test)^2)
}
sqrt(mean(err_save_lasso))
```
When we calculate RMSE for the backward selection model, it turned out to be `r round(sqrt(mean(err_save_lasso)),2)`.

### RandomForest

After this, we fit a RandomForest model and also did K-fold cross validation with the same baseline model we used in our lasso regression above. We started with 200 trees and as [Graph 3] shows 200 is enough to reduce our errors.

```{r 4.3.4, echo=FALSE, warning=FALSE}
err_save2 = rep(0, K)
for(i in 1:K){
  train_set2 = which(fold_id != i)
  y_test2 = texas_train$bmprison[-train_set2]
  model2_train = randomForest(bmprison ~ (crack + alcohol + income + ur + poverty + black 
                                          + perc1519 + aidscapita + year_fixed + statefip), data=texas_train[train_set2,], ntree=200)
  yhat_test2 = predict(model2_train, newdata = texas_train[-train_set2,])
  err_save2[i] = mean((y_test2-yhat_test2)^2)
}
plot(model2_train, main="[Graph 3] Number of trees vs error in Randomforest")
```
```{r 4.3.5, echo=FALSE, include=FALSE}
sqrt(mean(err_save2))
```

The K-fold validation result shows that the RMSE is `r round(sqrt(mean(err_save2)),2)` which is about 4 times larger than the RMSE of lasso regression.

### Boosting

Lastly, we used a boosting model with the same baseline model and did K-fold validation as we did above. 

```{r 4.3.6, echo=FALSE, warning=FALSE, include=FALSE}
err_save3 = rep(0, K)
for(i in 1:K){
  train_set3 = which(fold_id != i)
  y_test3 = texas_train$bmprison[-train_set3]
  model3_train <- gbm(bmprison ~ (crack + alcohol + income + ur + poverty + black 
                                  + perc1519 + aidscapita + year_fixed + statefip), data=texas_train[train_set3,], interaction.depth=4, n.trees = 200, shrinkage =.05)
  yhat_test3 = predict(model3_train, newdata = texas_train[-train_set3,], n.trees =200)
  err_save3[i] = mean((y_test3-yhat_test3)^2)
}

sqrt(mean(err_save3))
```

The result of our K-fold cross validation shows that the RMSE is `r round(sqrt(mean(err_save3)),2)` which is lower than the RandomForest model but still higher than the lasso regression. [Table 3] shows that the lasso regression has the best predictive power among all the models that we tested. 

```{r 4.3.7, echo=FALSE, warning=FALSE}
Model <- c('Lasso','Randomforest','Boosting')
RMSE <- c(round(sqrt(mean(err_save_lasso)),2), round(sqrt(mean(err_save2)),2),round(sqrt(mean(err_save3)),2))
RMSE_result = data.frame(Model,RMSE)
RMSE_result = t(RMSE_result)
pandoc.table(RMSE_result, caption="Table 2: RMSE Results for each model")
```

### Comparing the best model's predictions with the observed data

Since we have assessed our best predictive model, now we can compare its predictions with the real data in our whole data set. We can see how our prediction goes along with the real data in [Graph 3]. It shows the change of black male incarceration in the treated state, Texas, with 5 randomly chosen states.

```{r 4.3.8, echo=FALSE, warning=FALSE}
texas_general <- dummy.data.frame(texas, names = c("statefip", "year_fixed"))
texas_general$statefip = texas$statefip
texas_general$year_fixed = texas$year_fixed

model_lasso_test = lm(model_lasso, data=texas_lasso)
texas_general$yhat = predict(model_lasso_test, newdata = texas_general)

random_state = sample(as.numeric(unique(texas_general$statefip)), size=5)

subset(texas_general, statefip == 48 | statefip == random_state[1] | 
         statefip == random_state[2] | statefip == random_state[3] |
         statefip == random_state[4] | statefip == random_state[5]) %>%
  ggplot(aes(x = year, colour=state)) +
  geom_line(aes(y = bmprison)) +
  geom_line(aes(y = yhat), linetype = "dashed") +
  theme_bw() + ggtitle("[Graph 3] Prediction vs Real data by states") +
  xlab("Year") +
  ylab("Black Male Incarceration") +
  geom_vline(xintercept = 1993, color = "dark grey", size = 0.8) +
  theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank())

```

In [Graph 3], we can see two interesting findings. One is that Texas is showing clearly different movement from our predicted trend after the treatment in 1993. The other is that Our prediction from the lasso model fits very well on real data of controlled states.  

For inference purposes, it is recommended to estimate a confidence interval rather than showing the point estimate only. Therefore, we used a bootstrap to calculate the standard deviation of the parameter's resampling distribution. The results are ADD THE RESULTS AND PLOT

```{r 4.3.9, echo=FALSE, include=FALSE, cache=TRUE}
texas_lasso_inf = subset(texas, post == 0)
lasso_aux = texas_lasso_inf
texas_lasso_inf = dummy.data.frame(texas_lasso_inf, names = c("statefip", "year_fixed"))
texas_lasso_inf$statefip = lasso_aux$statefip
texas_lasso_inf$year_fixed = lasso_aux$year_fixed

texas_x_inf = sparse.model.matrix(bmprison ~ (crack + alcohol + income + ur + poverty + black  + perc1519 + aidscapita + year_fixed + statefip)^2, data=texas_lasso_inf)[, -1]
texas_y_inf = texas_lasso_inf$bmprison
reg_lasso_inf = gamlr(texas_x_inf, texas_y_inf)

texas_lasso_beta_inf = coef(reg_lasso_inf)
sum(texas_lasso_beta_inf!=0)
p1_inf <- dimnames(texas_lasso_beta_inf)[[1]]
p1_inf
p2_inf <- c()
p2_inf
for (i in c(1:length(texas_lasso_beta_inf))){
  p2_inf <- c(p2_inf, as.list(texas_lasso_beta_inf)[[i]])
}
model_lasso_inf = c("bmprison ~ ")
for (i in c(2:length(texas_lasso_beta_inf))){
  if (p2_inf[i] != 0){
    if (model_lasso_inf == "bmprison ~ "){
      model_lasso_inf = paste(model_lasso_inf, p1_inf[i])
    }
    else{
      model_lasso_inf = paste(model_lasso_inf,"+", p1_inf[i])
    }
  }
}
model_lasso_inf <- as.formula(model_lasso_inf)

texas_pred_inf = c(1:nrow(texas))
texas_pred_inf = as.data.frame(texas_pred_inf)

for(i in 1:1000) {
  train_resampling = resample(texas_lasso_inf)
  boot_train <- lm(model_lasso_inf, data=train_resampling)
  yhat = predict(boot_train, newdata = texas_general)
  texas_pred_inf = cbind(texas_pred_inf,yhat)
}

texas_pred_inf$texas_pred_inf = NULL
texas_pred_inf$mean = rowMeans(texas_pred_inf, na.rm = FALSE, dims = 1)
texas_pred_inf$se = apply(texas_pred_inf[,-1001], 1, sd)
texas_general$yhat_mean_inf = texas_pred_inf$mean
texas_general$yhat_se_inf = texas_pred_inf$se


```

```{r 4.3.10, echo=FALSE}
plot_texas = subset(texas_general, statefip == 48) %>%
  ggplot(aes(x = year, ymin = yhat_mean_inf-1.96*yhat_se_inf, ymax = yhat_mean_inf+1.96*yhat_se_inf)) +
  geom_line(aes(y = bmprison)) +
  geom_line(aes(y = yhat_mean_inf), color = "dark blue", linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf+1.96*yhat_se_inf), color = 'light blue',linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf-1.96*yhat_se_inf), color = 'light blue',linetype = "dashed")+
  geom_ribbon(alpha = 0.4, fill = "light blue") +
  ggtitle(texas_general$state[texas_general$statefip == 48]) +
  theme_bw() +
  xlab("Year") +
  ylab("Black Male Incarceration") +
  geom_vline(xintercept = 1993, color = "dark grey", size = 0.8) +
  theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(),
        plot.title = element_text(hjust = 0.5))

plot_1 = subset(texas_general, statefip == random_state[1]) %>%
  ggplot(aes(x = year, ymin = yhat_mean_inf-1.96*yhat_se_inf, ymax = yhat_mean_inf+1.96*yhat_se_inf)) +
  geom_line(aes(y = bmprison)) +
  geom_line(aes(y = yhat_mean_inf), color = "dark blue", linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf+1.96*yhat_se_inf), color = 'light blue',linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf-1.96*yhat_se_inf), color = 'light blue',linetype = "dashed")+
  geom_ribbon(alpha = 0.4, fill = "light blue") +
  ggtitle(texas_general$state[texas_general$statefip == random_state[1]]) +
  theme_bw() +
  xlab("Year") +
  ylab("Black Male Incarceration") +
  geom_vline(xintercept = 1993, color = "dark grey", size = 0.8) +
  theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(),
        plot.title = element_text(hjust = 0.5))

plot_2 = subset(texas_general, statefip == random_state[2]) %>%
  ggplot(aes(x = year, ymin = yhat_mean_inf-1.96*yhat_se_inf, ymax = yhat_mean_inf+1.96*yhat_se_inf)) +
  geom_line(aes(y = bmprison)) +
  geom_line(aes(y = yhat_mean_inf), color = "dark blue", linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf+1.96*yhat_se_inf), color = 'light blue',linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf-1.96*yhat_se_inf), color = 'light blue',linetype = "dashed")+
  geom_ribbon(alpha = 0.4, fill = "light blue") +
  ggtitle(texas_general$state[texas_general$statefip == random_state[2]]) +
  theme_bw() +
  xlab("Year") +
  ylab("Black Male Incarceration") +
  geom_vline(xintercept = 1993, color = "dark grey", size = 0.8) +
  theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(),
        plot.title = element_text(hjust = 0.5))

plot_3 = subset(texas_general, statefip == random_state[3]) %>%
  ggplot(aes(x = year, ymin = yhat_mean_inf-1.96*yhat_se_inf, ymax = yhat_mean_inf+1.96*yhat_se_inf)) +
  geom_line(aes(y = bmprison)) +
  geom_line(aes(y = yhat_mean_inf), color = "dark blue", linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf+1.96*yhat_se_inf), color = 'light blue',linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf-1.96*yhat_se_inf), color = 'light blue',linetype = "dashed")+
  geom_ribbon(alpha = 0.4, fill = "light blue") +
  ggtitle(texas_general$state[texas_general$statefip == random_state[3]]) +
  theme_bw() +
  xlab("Year") +
  ylab("Black Male Incarceration") +
  geom_vline(xintercept = 1993, color = "dark grey", size = 0.8) +
  theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(),
        plot.title = element_text(hjust = 0.5))

plot_4 = subset(texas_general, statefip == random_state[4]) %>%
  ggplot(aes(x = year, ymin = yhat_mean_inf-1.96*yhat_se_inf, ymax = yhat_mean_inf+1.96*yhat_se_inf)) +
  geom_line(aes(y = bmprison)) +
  geom_line(aes(y = yhat_mean_inf), color = "dark blue", linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf+1.96*yhat_se_inf), color = 'light blue',linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf-1.96*yhat_se_inf), color = 'light blue',linetype = "dashed")+
  geom_ribbon(alpha = 0.4, fill = "light blue") +
  ggtitle(texas_general$state[texas_general$statefip == random_state[4]]) +
  theme_bw() +
  xlab("Year") +
  ylab("Black Male Incarceration") +
  geom_vline(xintercept = 1993, color = "dark grey", size = 0.8) +
  theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(),
        plot.title = element_text(hjust = 0.5))

plot_5 = subset(texas_general, statefip == random_state[5]) %>%
  ggplot(aes(x = year, ymin = yhat_mean_inf-1.96*yhat_se_inf, ymax = yhat_mean_inf+1.96*yhat_se_inf)) +
  geom_line(aes(y = bmprison)) +
  geom_line(aes(y = yhat_mean_inf), color = "dark blue", linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf+1.96*yhat_se_inf), color = 'light blue',linetype = "dashed") +
  geom_line(aes(y = yhat_mean_inf-1.96*yhat_se_inf), color = 'light blue',linetype = "dashed")+
  geom_ribbon(alpha = 0.4, fill = "light blue") +
  ggtitle(texas_general$state[texas_general$statefip == random_state[5]]) +
  theme_bw() +
  xlab("Year") +
  ylab("Black Male Incarceration") +
  geom_vline(xintercept = 1993, color = "dark grey", size = 0.8) +
  theme(panel.grid.minor = element_blank(), panel.grid.major.x = element_blank(),
        plot.title = element_text(hjust = 0.5))

panel_1 = grid.arrange(layout_matrix = cbind(c(1,2,3),c(4,5,6)),
                       plot_texas, plot_1, plot_2, plot_3,plot_4, plot_5, ncol=3)

panel_1 = grid.arrange(plot_texas, plot_2, ncol=2)
```

```{r 4.3.11, echo=FALSE}
texas_post = subset(texas_general, post == 1)
texas_post$dhat = (texas_post$bmprison - texas_post$yhat_mean_inf)
mean(texas_post$dhat)
```

## Conclusion

The analysis showed that alternative supervised learning methods can play a big role in predicting counterfactuals when there are reasons to believe that the traditional assumptions don't hold. It is important to notice that it is upon to the researcher's discretion how to do it in practice, and it might open up space for "p-hacking" when moving away from the best practices. In that sense, peer review/validation is crucial to ensure that the predictions are being yielded by models that minimize out of sample root mean square error, and randomness is fundamental to guarantee that the results aren't being conveniently tampered.  
Our dataset has only 816 observations due to the limitation of number of states and time span. We could have increased our model's predictive power if we had had more observations, however, our model fits very well on real data of contolled states suggesting the possibility of predicting counterfactuals.

## References

Wooldridge, J.M. (2013). Introductory econometrics: A modern approach

Angrist, J and Pischke, J.S. (2018). Mostly Harmless Econometrics

Cunningham, Scott (2020). CAUSAL INFERENCE: THE MIXTAPE

Abadie, A, Diamond, A and Hainmueller, J (2010). Synthetic Control Methods for Comparative Case Studies: Estimating the Effect of California’s Tobacco Control Program

Kearney, M.S. and Levine, P.B. (2015) Media Influences on Social Outcomes: The Impact of MTV's 16 and Pregnant on Teen Childbearing
